# Investigation of Generative Adversarial Networks and Their Comparative Parametric Analysis

The performance of GANs is highly dependent on their hyperparameters and architecture, and selecting the best set of parameters
can be challenging. This paper investigates the performance of different GAN architectures and their corresponding hyperparameters through a comprehensive comparative parametric analysis. We evaluate the performance of GANs using multiple quantitative metrics such as Fréchet Inception Distance (FID), F1 score, precision and recall. This study comprehensively evaluates GANs and their parameters, enabling researchers and practitioners to make informed decisions when using GANs for synthetic data generation.

## Types of GANs picked for this reasearch work
- Vanilla GAN
- Least Squares GAN (LSGAN)
- Wasserstein GAN (WGAN)
- Wasserstein GAN with Gradient Penalty (WGAN GP)

## The Parameters
<p align="center">
  <img src="imgs/Screenshot 2023-05-28 at 21.37.31.png" width="350">
</p>
The range of hyper-parameters used to do the evaluation and analysis. “U” denotes
uniform sampling and “L” denotes sampling on a log scale. (a,b) indicates a range of parameters.

## Obtained Results
<p align="center">
  <img src="imgs/Screenshot 2023-05-28 at 21.36.41.png" width="350">
</p>

## Data
<p align="center">
  <img src="imgs/1_7WqgL4L9p0DOA8-aEeoFpw.gif" width="350">
</p>

## The codes/notebooks
All the .ipynb files are available in "collect_into_one_architecture" folder

## The Results
The results are in **result** folders where you can also find all the saved models.

## The Paper
In the paper you can find detailed explanaition of each Generative Adversaarial Network model, their **fair** comparative parametric analysis and the obtained results and conclusions.

